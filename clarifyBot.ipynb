{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcYF4ovq4gHc/iV8FnVn9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalsalilan/Infosys-Springboard-Virtual-Internship-6.0-Open-Deep-Researcher-batch-2/blob/Prateek_Ray/clarifyBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fpxKWxPnlbjj",
        "outputId": "9c732e8f-2fc6-4155-e869-0e5e43a070cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: google-generativeai 0.8.5\n",
            "Uninstalling google-generativeai-0.8.5:\n",
            "  Successfully uninstalled google-generativeai-0.8.5\n",
            "Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "  Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "Collecting google-generativeai==0.8.5\n",
            "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-ai-generativelanguage==0.7.0\n",
            "  Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install google-ai-generativelanguage==0.7.0 and google-generativeai==0.8.5 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested google-ai-generativelanguage==0.7.0\n",
            "    google-generativeai 0.8.5 depends on google-ai-generativelanguage==0.6.15\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.75)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Collecting filetype<2,>=1.2 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 google-ai-generativelanguage-0.7.0 langchain-google-genai-2.1.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "aa52b3c3b9e84dffa6315dcfb449ccbb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y google-generativeai google-ai-generativelanguage\n",
        "!pip install google-generativeai==0.8.5 google-ai-generativelanguage==0.7.0\n",
        "!pip install --upgrade langchain-google-genai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBLmOBUTlpjL",
        "outputId": "1fb948a0-014c-49b3-b5d4-63aabdcf6450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.75)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.27)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Optional, Dict\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR_API_KEY\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"clarify-chatbot\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\" , temperature=0)"
      ],
      "metadata": {
        "id": "CodpSDajly9h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Optional, Dict\n",
        "\n",
        "class ClarifyState(TypedDict):\n",
        "    query: str\n",
        "    missing_info: Optional[str]\n",
        "    clarification: Optional[str]\n",
        "    answer: Optional[str]\n",
        "    memory: Dict[str, str]"
      ],
      "metadata": {
        "id": "rQXb4PiWmBc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_node(state: ClarifyState):\n",
        "    memory_str = \"\\n\".join([f\"{k}: {v}\" for k, v in state.get(\"memory\", {}).items()])\n",
        "    raw = analysis_chain.invoke({\n",
        "        \"query\": state.get(\"query\", \"\"),\n",
        "        \"memory_str\": memory_str\n",
        "    }).get(\"text\", \"\")\n",
        "\n",
        "    if raw.strip().startswith(\"CLARIFY:\"):\n",
        "        state[\"missing_info\"] = raw.replace(\"CLARIFY:\", \"\").strip()\n",
        "    else:\n",
        "        state[\"missing_info\"] = None\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "xVSkW3EDmC6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clarify_node(state: ClarifyState):\n",
        "    \"\"\"Ask the user for missing info and store it into memory.\"\"\"\n",
        "    missing_info = state.get(\"missing_info\")\n",
        "    if missing_info:\n",
        "\n",
        "        print(\"Bot:\", f\"Can you clarify: {missing_info}?\")\n",
        "        user_ans = input(\"You (clarification): \").strip()\n",
        "\n",
        "        if user_ans.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            exit()\n",
        "\n",
        "        state[\"clarification\"] = user_ans\n",
        "\n",
        "        lower_ans = user_ans.lower()\n",
        "        if \"my name is\" in lower_ans:\n",
        "            name = user_ans.split(\"my name is\")[-1].strip().split()[0]\n",
        "            state[\"memory\"][\"name\"] = name\n",
        "        elif \"i live in\" in lower_ans or \"my city is\" in lower_ans:\n",
        "            city = user_ans.replace(\"i live in\", \"\").replace(\"my city is\", \"\").strip()\n",
        "            state[\"memory\"][\"city\"] = city\n",
        "        else:\n",
        "\n",
        "            key = missing_info.replace(\" \", \"_\").lower()\n",
        "            state[\"memory\"][key] = user_ans\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "BPSY1yGImgTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "analysis_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"memory_str\"],\n",
        "    template=\"\"\"\n",
        "Here is what you know about the user so far:\n",
        "{memory_str}\n",
        "\n",
        "Check if the user query needs clarification.\n",
        "If the query can be answered with the information in memory, say \"OK\".\n",
        "If you still need information, say:\n",
        "CLARIFY: <what you need>\n",
        "\n",
        "User query: {query}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "analysis_chain = LLMChain(llm=llm, prompt=analysis_prompt)\n",
        "\n",
        "def analyze_node(state: ClarifyState):\n",
        "    memory_str = \"\\n\".join([f\"{k}: {v}\" for k, v in state[\"memory\"].items()])\n",
        "\n",
        "    raw_result = analysis_chain.invoke({\n",
        "        \"query\": state[\"query\"],\n",
        "        \"memory_str\": memory_str\n",
        "    })\n",
        "    raw = raw_result[\"text\"] if isinstance(raw_result, dict) and \"text\" in raw_result else str(raw_result)\n",
        "\n",
        "    if raw.strip().startswith(\"CLARIFY:\"):\n",
        "        state[\"missing_info\"] = raw.replace(\"CLARIFY:\", \"\").strip()\n",
        "    else:\n",
        "        state[\"missing_info\"] = None\n",
        "    return state\n",
        "\n",
        "\n",
        "answer_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"clarification\", \"memory_str\"],\n",
        "    template=\"\"\"\n",
        "You are a helpful assistant. Use the user's memory and any clarifications to answer.\n",
        "\n",
        "Memory:\n",
        "{memory_str}\n",
        "\n",
        "Clarification (if any):\n",
        "{clarification}\n",
        "\n",
        "User query:\n",
        "{query}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "answer_chain = LLMChain(llm=llm, prompt=answer_prompt)\n",
        "\n",
        "def answer_node(state: ClarifyState):\n",
        "    clarification = state.get(\"clarification\") or \"\"\n",
        "    memory_str = \"\\n\".join([f\"{k}: {v}\" for k, v in state[\"memory\"].items()])\n",
        "\n",
        "    ans = answer_chain.run({\n",
        "        \"query\": state[\"query\"],\n",
        "        \"clarification\": clarification,\n",
        "        \"memory_str\": memory_str\n",
        "    })\n",
        "\n",
        "    state[\"answer\"] = ans\n",
        "    print(\"Bot:\", ans)\n",
        "\n",
        "    text_lower = (state[\"query\"] + \" \" + clarification + \" \" + ans).lower()\n",
        "    if \"my name is\" in text_lower:\n",
        "        name = state[\"query\"].split(\"my name is\")[-1].strip().split()[0]\n",
        "        state[\"memory\"][\"name\"] = name\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "UBih7jwJm3Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "followup_prompt = PromptTemplate(\n",
        "    input_variables=[\"answer\"],\n",
        "    template=\"\"\"Suggest 3 very short follow-up questions. Number them 1, 2, 3.\n",
        "Answer: {answer}\"\"\"\n",
        ")\n",
        "\n",
        "followup_chain = LLMChain(llm=llm, prompt=followup_prompt)\n",
        "\n",
        "def suggest_followups(answer):\n",
        "    suggestions_str = followup_chain.run({\"answer\": answer})\n",
        "    suggestions = [\n",
        "        line.split('.', 1)[-1].strip()\n",
        "        for line in suggestions_str.split('\\n')\n",
        "        if line.strip()\n",
        "    ]\n",
        "\n",
        "    print(\"\\nPossible follow-ups:\")\n",
        "    for i, s in enumerate(suggestions, 1):\n",
        "        print(f\"{i}. {s}\")\n",
        "\n",
        "    return suggestions\n"
      ],
      "metadata": {
        "id": "yLTB0EjInj8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def update_memory_from_text(text, memory_dict):\n",
        "    \"\"\"Look for patterns like 'my name is X' or 'I live in Y' and store them.\"\"\"\n",
        "    lower = text.lower()\n",
        "\n",
        "    match_name = re.search(r\"my name is ([a-zA-Z ]+)\", lower)\n",
        "    if match_name:\n",
        "        memory_dict[\"name\"] = match_name.group(1).strip().title()\n",
        "\n",
        "    match_city = re.search(r\"(i live in|my city is) ([a-zA-Z ]+)\", lower)\n",
        "    if match_city:\n",
        "        memory_dict[\"city\"] = match_city.group(2).strip().title()\n",
        "\n",
        "    return memory_dict\n"
      ],
      "metadata": {
        "id": "KNVeYf89qwjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(ClarifyState)\n",
        "workflow.add_node(\"analyze\", analyze_node)\n",
        "workflow.add_node(\"clarify\", clarify_node)\n",
        "workflow.add_node(\"answer\", answer_node)\n",
        "\n",
        "workflow.set_entry_point(\"analyze\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"analyze\",\n",
        "    lambda s: \"clarify\" if s[\"missing_info\"] else \"answer\",\n",
        "    {\"clarify\": \"clarify\", \"answer\": \"answer\"}\n",
        ")\n",
        "workflow.add_edge(\"clarify\",\"answer\")\n",
        "workflow.add_edge(\"answer\", END)\n",
        "\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "6iw4mbDobQhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clarify_with_user_memory():\n",
        "    print(\"Type 'exit' to quit.\\n\")\n",
        "    memory_dict = {}\n",
        "    followups = []\n",
        "\n",
        "    while True:\n",
        "        if followups:\n",
        "            user_query = input(\"You (or choose 1/2/3): \")\n",
        "            if user_query.isdigit():\n",
        "                idx = int(user_query)\n",
        "                if 1 <= idx <= len(followups):\n",
        "                    user_query = followups[idx - 1]\n",
        "                    print(f\"You selected follow-up: {user_query}\")\n",
        "        else:\n",
        "            user_query = input(\"You: \")\n",
        "\n",
        "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        memory_dict = update_memory_from_text(user_query, memory_dict)\n",
        "\n",
        "        state = {\n",
        "            \"query\": user_query,\n",
        "            \"missing_info\": None,\n",
        "            \"clarification\": None,\n",
        "            \"answer\": None,\n",
        "            \"memory\": memory_dict\n",
        "        }\n",
        "\n",
        "        final_state = app.invoke(state)\n",
        "\n",
        "        memory_dict.update(final_state[\"memory\"])\n",
        "        memory_dict = update_memory_from_text(final_state[\"answer\"], memory_dict)\n",
        "\n",
        "        followups = suggest_followups(final_state[\"answer\"])\n",
        "\n",
        "        print(\"Current memory:\", memory_dict)\n"
      ],
      "metadata": {
        "id": "QGlJLUV5q0oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clarify_with_user_memory()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fwmziUyrX_j",
        "outputId": "9002e871-95d3-4ea9-c352-d4fefd99b1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 'exit' to quit.\n",
            "\n",
            "You: hello\n",
            "Bot: Hello! How can I help you today?\n",
            "\n",
            "Possible follow-ups:\n",
            "1. Here are 3 very short follow-up questions:\n",
            "2. What's your goal?\n",
            "3. What are you looking for?\n",
            "4. What's the issue?\n",
            "Current memory: {}\n",
            "You (or choose 1/2/3): can you suggest some good coffee shop\n",
            "Bot: Can you clarify: What city or area are you interested in? Do you have any preferences, like a quiet place to work, a lively atmosphere, specific coffee types, or food options??\n",
            "You (clarification): delhi,nehru place\n",
            "Bot: Based on your interest in Delhi, Nehru Place, here are some good coffee shop suggestions:\n",
            "\n",
            "1.  **Starbucks:** A popular choice, known for its wide range of coffee, comfortable seating, and often a good place to work.\n",
            "2.  **The Coffee Bean & Tea Leaf:** Another international chain offering a variety of coffee and tea options, often a relaxed atmosphere.\n",
            "3.  **Cafe Coffee Day (CCD):** A well-known Indian chain, good for a quick coffee and snacks, usually has ample seating.\n",
            "4.  **Chaayos:** While primarily a tea chain, they also serve coffee and have a great selection of snacks and a casual, comfortable environment.\n",
            "\n",
            "Possible follow-ups:\n",
            "1. Here are 3 very short follow-up questions:\n",
            "2. Which one is best for a quiet work session?\n",
            "3. Do any offer unique local snacks?\n",
            "4. Are they generally budget-friendly?\n",
            "Current memory: {'what_city_or_area_are_you_interested_in?_do_you_have_any_preferences,_like_a_quiet_place_to_work,_a_lively_atmosphere,_specific_coffee_types,_or_food_options?': 'delhi,nehru place'}\n",
            "You (or choose 1/2/3): place with good atmosphere and good music\n",
            "Bot: Based on your interest in Nehru Place, Delhi, and your preference for a good atmosphere and good music, you might enjoy **The Chatter House**. It's known for its lively pub-like ambiance and good music selection.\n",
            "\n",
            "Possible follow-ups:\n",
            "1. Any specific music genre you prefer?\n",
            "2. Are you looking for food as well, or just drinks?\n",
            "3. Is Nehru Place a convenient location for you?\n",
            "Current memory: {'what_city_or_area_are_you_interested_in?_do_you_have_any_preferences,_like_a_quiet_place_to_work,_a_lively_atmosphere,_specific_coffee_types,_or_food_options?': 'delhi,nehru place'}\n",
            "You (or choose 1/2/3): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}