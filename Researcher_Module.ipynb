{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-genai langgraph typing-extensions pydantic==2.9.2 validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60051620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydantic import BaseModel, Field, field_validator, ValidationError\n",
    "from typing import Optional, Dict, Any, List\n",
    "from datetime import datetime\n",
    "import re\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyARvUEHkan-yQuL6Kfhy3XDFmG4Z6x_WP8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fa58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchBriefModel(BaseModel):\n",
    "    topic: Optional[str] = Field(None, description=\"The research topic\")\n",
    "    objective: Optional[str] = Field(None, description=\"Objective of the research\")\n",
    "    audience: Optional[str] = Field(None, description=\"Target audience\")\n",
    "    timeframe: Optional[str] = Field(None, description=\"Time horizon\")\n",
    "    depth: Optional[str] = Field(None, description=\"Depth required (summary, detailed, etc.)\")\n",
    "    deliverable: Optional[str] = Field(None, description=\"Format: brief, slides, report\")\n",
    "    constraints: Optional[str] = Field(None, description=\"Special constraints, if any\")\n",
    "    notes: Optional[str] = Field(None, description=\"Extra notes\")\n",
    "\n",
    "    @field_validator(\"depth\", mode=\"before\")\n",
    "    def normalize_depth(cls, v):\n",
    "        if isinstance(v, str):\n",
    "            return v.lower().strip()\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa21be",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_FIELDS = {\"topic\", \"objective\", \"audience\", \"depth\", \"deliverable\"}\n",
    "\n",
    "MISSING_TO_QUESTION = {\n",
    "    \"topic\": \"What's the exact research topic? (include domain and focus)\",\n",
    "    \"objective\": \"What's the objective? (summary, literature review, recommendations, etc.)\",\n",
    "    \"audience\": \"Who is the primary audience? (doctors, policymakers, students, etc.)\",\n",
    "    \"timeframe\": \"Any timeframe or date range for the research?\",\n",
    "    \"depth\": \"What depth do you want? (summary, detailed, deep)\",\n",
    "    \"deliverable\": \"What is the deliverable? (brief, slides, notebook, report)\",\n",
    "    \"constraints\": \"Any constraints? (data, budget, non-English, ethical, formats)\",\n",
    "    \"notes\": \"Any extra notes?\"\n",
    "}\n",
    "\n",
    "def parse_fields_from_text(text: str) -> Dict[str, str]:\n",
    "    \"\"\"Basic heuristics to extract fields from user input\"\"\"\n",
    "    fields = {}\n",
    "    lowered = text.lower()\n",
    "\n",
    "    if \"research\" in lowered or \"impact\" in lowered or \"ai\" in lowered:\n",
    "        fields[\"topic\"] = text.split(\".\")[0].strip()\n",
    "\n",
    "    for obj in [\"summary\", \"literature review\", \"method comparison\", \"recommendations\", \"roadmap\", \"data analysis\", \"product spec\"]:\n",
    "        if obj in lowered:\n",
    "            fields[\"objective\"] = obj\n",
    "            break\n",
    "    if \"clinicians\" in lowered:\n",
    "        fields[\"audience\"] = \"clinicians\"\n",
    "    elif \"officer\" in lowered or \"public health\" in lowered:\n",
    "        fields[\"audience\"] = \"public health officers\"\n",
    "\n",
    "    if \"brief\" in lowered:\n",
    "        fields[\"deliverable\"] = \"brief\"\n",
    "    elif \"slides\" in lowered or \"deck\" in lowered:\n",
    "        fields[\"deliverable\"] = \"slides\"\n",
    "\n",
    "    if \"summary\" in lowered:\n",
    "        fields[\"depth\"] = \"summary\"\n",
    "    elif \"detailed\" in lowered:\n",
    "        fields[\"depth\"] = \"detailed\"\n",
    "    elif \"deep\" in lowered:\n",
    "        fields[\"depth\"] = \"deep\" \n",
    "\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed955f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_missing_and_questions(fields: Dict[str, str]) -> Dict[str, Any]:\n",
    "    present = set(k for k, v in fields.items() if v and str(v).strip())\n",
    "    missing = list(REQUIRED_FIELDS - present)\n",
    "    questions = [MISSING_TO_QUESTION[f] for f in missing if f in MISSING_TO_QUESTION]\n",
    "    return {\"clarify\": bool(questions), \"missing_fields\": missing, \"questions\": questions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structured_brief(fields: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    try:\n",
    "        brief = ResearchBriefModel(**fields)\n",
    "    except ValidationError as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "    md_lines = [\n",
    "        f\"# Research Brief — {brief.topic or 'N/A'}\",\n",
    "        f\"**Generated:** {datetime.now().isoformat()}\",\n",
    "        f\"**Objective:** {brief.objective or 'N/A'}\",\n",
    "        f\"**Audience:** {brief.audience or 'N/A'}\",\n",
    "        f\"**Depth:** {brief.depth or 'N/A'}\",\n",
    "        f\"**Deliverable:** {brief.deliverable or 'N/A'}\"\n",
    "    ]\n",
    "\n",
    "    if brief.timeframe:\n",
    "        md_lines.append(f\"**Timeframe:** {brief.timeframe}\")\n",
    "    if brief.constraints:\n",
    "        md_lines.append(f\"**Constraints:** {brief.constraints}\")\n",
    "    if brief.notes:\n",
    "        md_lines.append(f\"**Notes:** {brief.notes}\")\n",
    "\n",
    "    return {\"structured\": brief.model_dump(), \"markdown\": \"\\n\".join(md_lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input() -> Dict[str, str]:\n",
    "    fields = {}\n",
    "    fields[\"topic\"] = input(\"Enter the research topic: \")\n",
    "    fields[\"objective\"] = input(\"Enter the objective (summary, recommendations, etc.): \")\n",
    "    fields[\"audience\"] = input(\"Enter the audience (doctors, policymakers, etc.): \")\n",
    "    fields[\"timeframe\"] = input(\"Enter the timeframe (optional): \")\n",
    "    fields[\"depth\"] = input(\"Enter the depth (summary/detailed): \")\n",
    "    fields[\"deliverable\"] = input(\"Enter the deliverable (brief/slides/etc.): \")\n",
    "    fields[\"constraints\"] = input(\"Enter constraints (if any): \")\n",
    "    fields[\"notes\"] = input(\"Enter any notes (optional): \")\n",
    "    return fields\n",
    "\n",
    "user_fields = get_user_input()\n",
    "clarification = determine_missing_and_questions(user_fields)\n",
    "\n",
    "if clarification[\"clarify\"]:\n",
    "    print(\"\\n Some fields are missing. Please provide:\")\n",
    "    for q in clarification[\"questions\"]:\n",
    "        print(\"-\", q)\n",
    "\n",
    "brief = create_structured_brief(user_fields)\n",
    "print(\"\\n Generated Research Brief:\\n\")\n",
    "print(brief[\"markdown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7023bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade google-genai langgraph typing-extensions pydantic==2.9.2 validators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field, field_validator, ValidationError\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyARvUEHkan-yQuL6Kfhy3XDFmG4Z6x_WP8\"  \n",
    "\n",
    "from google import genai\n",
    "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2306c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchBriefModel(BaseModel):\n",
    "    topic: Optional[str] = Field(None, description=\"The research topic\")\n",
    "    objective: Optional[str] = Field(None, description=\"Objective of the research\")\n",
    "    audience: Optional[str] = Field(None, description=\"Target audience\")\n",
    "    timeframe: Optional[str] = Field(None, description=\"Time horizon\")\n",
    "    depth: Optional[str] = Field(None, description=\"Depth required (summary, detailed, etc.)\")\n",
    "    deliverable: Optional[str] = Field(None, description=\"Format: brief, slides, report\")\n",
    "    constraints: Optional[str] = Field(None, description=\"Special constraints, if any\")\n",
    "    notes: Optional[str] = Field(None, description=\"Extra notes\")\n",
    "\n",
    "    @field_validator(\"depth\", mode=\"before\")\n",
    "    def normalize_depth(cls, v):\n",
    "        if isinstance(v, str):\n",
    "            return v.lower().strip()\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6cfad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_FIELDS = {\"topic\", \"objective\", \"audience\", \"depth\", \"deliverable\"}\n",
    "\n",
    "MISSING_TO_QUESTION = {\n",
    "    \"topic\": \"What's the exact research topic? (include domain and focus)\",\n",
    "    \"objective\": \"What's the objective? (summary, literature review, recommendations, etc.)\",\n",
    "    \"audience\": \"Who is the primary audience? (doctors, policymakers, students, etc.)\",\n",
    "    \"timeframe\": \"Any timeframe or date range for the research?\",\n",
    "    \"depth\": \"What depth do you want? (summary, detailed, deep)\",\n",
    "    \"deliverable\": \"What is the deliverable? (brief, slides, notebook, report)\",\n",
    "    \"constraints\": \"Any constraints? (data, budget, non-English, ethical, formats)\",\n",
    "    \"notes\": \"Any extra notes?\"\n",
    "}\n",
    "\n",
    "def parse_fields_from_text(text: str) -> Dict[str, str]:\n",
    "    fields = {}\n",
    "    lowered = text.lower()\n",
    "\n",
    "    if \"research\" in lowered or \"impact\" in lowered or \"ai\" in lowered:\n",
    "        fields[\"topic\"] = text.split(\".\")[0].strip()\n",
    "\n",
    "    for obj in [\"summary\", \"literature review\", \"method comparison\", \"recommendations\", \"roadmap\", \"data analysis\", \"product spec\"]:\n",
    "        if obj in lowered:\n",
    "            fields[\"objective\"] = obj\n",
    "            break\n",
    "    if \"clinicians\" in lowered:\n",
    "        fields[\"audience\"] = \"clinicians\"\n",
    "    elif \"officer\" in lowered or \"public health\" in lowered:\n",
    "        fields[\"audience\"] = \"public health officers\"\n",
    "\n",
    "    if \"brief\" in lowered:\n",
    "        fields[\"deliverable\"] = \"brief\"\n",
    "    elif \"slides\" in lowered or \"deck\" in lowered:\n",
    "        fields[\"deliverable\"] = \"slides\"\n",
    "\n",
    "    if \"summary\" in lowered:\n",
    "        fields[\"depth\"] = \"summary\"\n",
    "    elif \"detailed\" in lowered:\n",
    "        fields[\"depth\"] = \"detailed\"\n",
    "    elif \"deep\" in lowered:\n",
    "        fields[\"depth\"] = \"deep\"\n",
    "\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_missing_and_questions(fields: Dict[str, str]) -> Dict[str, Any]:\n",
    "    present = set(k for k, v in fields.items() if v and str(v).strip())\n",
    "    missing = list(REQUIRED_FIELDS - present)\n",
    "    questions = [MISSING_TO_QUESTION[f] for f in missing if f in MISSING_TO_QUESTION]\n",
    "    return {\"clarify\": bool(questions), \"missing_fields\": missing, \"questions\": questions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structured_brief(fields: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    try:\n",
    "        brief = ResearchBriefModel(**fields)\n",
    "    except ValidationError as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "    md_lines = [\n",
    "        f\"# Research Brief — {brief.topic or 'N/A'}\",\n",
    "        f\"**Generated:** {datetime.now(timezone.utc).isoformat()}\",\n",
    "        f\"**Objective:** {brief.objective or 'N/A'}\",\n",
    "        f\"**Audience:** {brief.audience or 'N/A'}\",\n",
    "        f\"**Depth:** {brief.depth or 'N/A'}\",\n",
    "        f\"**Deliverable:** {brief.deliverable or 'N/A'}\"\n",
    "    ]\n",
    "    if brief.timeframe:\n",
    "        md_lines.append(f\"**Timeframe:** {brief.timeframe}\")\n",
    "    if brief.constraints:\n",
    "        md_lines.append(f\"**Constraints:** {brief.constraints}\")\n",
    "    if brief.notes:\n",
    "        md_lines.append(f\"**Notes:** {brief.notes}\")\n",
    "\n",
    "    return {\"structured\": brief.model_dump(), \"markdown\": \"\\n\".join(md_lines)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05efdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polish_brief_with_gemini(markdown_text: str, model=\"gemini-2.5-flash\") -> str:\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=markdown_text\n",
    "    )\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_module():\n",
    "    user_input = input(\"Enter your research request: \")\n",
    "    \n",
    "    fields = parse_fields_from_text(user_input)\n",
    "    \n",
    "    clarification = determine_missing_and_questions(fields)\n",
    "    if clarification[\"clarify\"]:\n",
    "        print(\"\\n Some fields are missing. Please provide:\")\n",
    "        for q in clarification[\"questions\"]:\n",
    "            answer = input(f\"{q} \")\n",
    "            key = [k for k,v in MISSING_TO_QUESTION.items() if v == q][0]\n",
    "            fields[key] = answer.strip()\n",
    "    \n",
    "    brief = create_structured_brief(fields)\n",
    "    print(\"\\n Structured Brief:\\n\")\n",
    "    print(brief[\"markdown\"])\n",
    "    \n",
    "    polished = polish_brief_with_gemini(brief[\"markdown\"])\n",
    "    print(\"\\n Polished Brief (Gemini AI):\\n\")\n",
    "    print(polished)\n",
    "\n",
    "researcher_module()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8ec013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "\n",
    "MAX_ITERATIONS = 3\n",
    "MAX_CHARS_BRIEF = 60\n",
    "KOLKATA_TZ_OFFSET = timedelta(hours=5, minutes=30)\n",
    "\n",
    "class ResearcherOutput(BaseModel):\n",
    "    text: str\n",
    "    brief: bool\n",
    "\n",
    "    @field_validator(\"text\")\n",
    "    @classmethod\n",
    "    def strip_whitespace(cls, v: str) -> str:\n",
    "        return v.strip()\n",
    "\n",
    "    def validate_briefness(self, max_chars: int = MAX_CHARS_BRIEF) -> None:\n",
    "        if len(self.text) > max_chars:\n",
    "            raise ValidationError(\n",
    "                [f\"Output too long ({len(self.text)} chars > {max_chars}).\"], model=type(self)\n",
    "            )\n",
    "\n",
    "def call_gemini(prompt: str, max_tokens: int = 150, temperature: float = 0.0) -> str:\n",
    "    return f\"[LLM STUB] Reply to: {prompt[:200]}\"\n",
    "def is_date_query(query: str) -> bool:\n",
    "    q = query.lower().strip()\n",
    "    patterns = [\n",
    "        r\"what(?:'s| is)?\\s+today('?s)?\\s+date\",\n",
    "        r\"today('?s)?\\s+date\",\n",
    "        r\"date\\s+today\",\n",
    "        r\"give\\s+me\\s+today('?s)?\\s+date\",\n",
    "    ]\n",
    "    return any(re.search(p, q) for p in patterns)\n",
    "\n",
    "def local_date_string(fmt: str = \"%d.%m.%Y\") -> str:\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    now_local = now_utc + KOLKATA_TZ_OFFSET\n",
    "    return now_local.strftime(fmt)\n",
    "\n",
    "def researcher_reflection(query: str, max_iters: int = MAX_ITERATIONS) -> ResearcherOutput:\n",
    "    if is_date_query(query):\n",
    "        date_str = local_date_string()\n",
    "        return ResearcherOutput(text=date_str, brief=True)\n",
    "\n",
    "    generator_prompt = (\n",
    "        \"You are a concise researcher. \"\n",
    "        \"Answer briefly (≤60 characters). \"\n",
    "        f\"User query: {query}\\nBrief answer:\"\n",
    "    )\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        gen_resp = call_gemini(generator_prompt).strip()\n",
    "        brief_flag = len(gen_resp) <= MAX_CHARS_BRIEF\n",
    "        out = ResearcherOutput(text=gen_resp, brief=brief_flag)\n",
    "\n",
    "        if brief_flag:\n",
    "            try:\n",
    "                out.validate_briefness()\n",
    "                return out\n",
    "            except ValidationError:\n",
    "                pass\n",
    "            critic_prompt = (\n",
    "            \"Rewrite this answer to be under 60 characters \"\n",
    "            \"and preserve only the essential fact.\\n\\n\"\n",
    "            f\"Answer:\\n{gen_resp}\\n\\nBrief rewrite:\"\n",
    "        )\n",
    "        rewrite = call_gemini(critic_prompt).strip()\n",
    "\n",
    "        if len(rewrite) <= MAX_CHARS_BRIEF:\n",
    "            return ResearcherOutput(text=rewrite, brief=True)\n",
    "\n",
    "        generator_prompt = (\n",
    "            f\"User query: {query}\\n\"\n",
    "            \"Give a one-line factual answer under 60 characters.\\nBrief answer:\"\n",
    "        )\n",
    "\n",
    "    truncated = out.text[:MAX_CHARS_BRIEF].rstrip(\" ,:;\")\n",
    "    return ResearcherOutput(text=truncated, brief=True)\n",
    "\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\nEnter your research query (type 'exit' to stop): \").strip()\n",
    "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"\\n Exiting Reflection Researcher. Goodbye!\\n\")\n",
    "        break\n",
    "\n",
    "    result = researcher_reflection(query)\n",
    "    print(f\"\\n AI is reflecting on your query...\\n\")\n",
    "    print(f\"Query: {query}\\n→ {result.text}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9355c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyARvUEHkan-yQuL6Kfhy3XDFmG4Z6x_WP8\")\n",
    "\n",
    "def call_gemini(prompt: str, max_tokens: int = 150, temperature: float = 0.0) -> str:\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": temperature,\n",
    "                \"max_output_tokens\": max_tokens,\n",
    "            }\n",
    "        )\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[Gemini Error] {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72605472",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5764ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyARvUEHkan-yQuL6Kfhy3XDFmG4Z6x_WP8\"\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747da078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, ValidationError, field_validator\n",
    "\n",
    "MAX_ITERATIONS = 3\n",
    "MAX_CHARS_BRIEF = 60\n",
    "KOLKATA_TZ_OFFSET = timedelta(hours=5, minutes=30)\n",
    "\n",
    "class ResearcherOutput(BaseModel):\n",
    "    text: str\n",
    "    brief: bool\n",
    "\n",
    "    @field_validator(\"text\")\n",
    "    @classmethod\n",
    "    def strip_whitespace(cls, v: str) -> str:\n",
    "        return v.strip()\n",
    "\n",
    "    def validate_briefness(self, max_chars: int = MAX_CHARS_BRIEF) -> None:\n",
    "        if len(self.text) > max_chars:\n",
    "            raise ValidationError(\n",
    "                [f\"Output too long ({len(self.text)} chars > {max_chars}).\"], model=type(self)\n",
    "            )\n",
    "\n",
    "def call_gemini(prompt: str, max_tokens: int = 150, temperature: float = 0.0) -> str:\n",
    "    return f\"[LLM STUB] Reply to: {prompt[:200]}\"\n",
    "    def is_date_query(query: str) -> bool:\n",
    "    q = query.lower().strip()\n",
    "    patterns = [\n",
    "        r\"what(?:'s| is)?\\s+today('?s)?\\s+date\",\n",
    "        r\"today('?s)?\\s+date\",\n",
    "        r\"date\\s+today\",\n",
    "        r\"give\\s+me\\s+today('?s)?\\s+date\",\n",
    "    ]\n",
    "    return any(re.search(p, q) for p in patterns)\n",
    "def local_date_string(fmt: str = \"%d.%m.%Y\") -> str:\n",
    "    now_utc = datetime.now(timezone.utc)\n",
    "    now_local = now_utc + KOLKATA_TZ_OFFSET\n",
    "    return now_local.strftime(fmt)\n",
    "\n",
    "def researcher_reflection(query: str, max_iters: int = MAX_ITERATIONS) -> ResearcherOutput:\n",
    "    if is_date_query(query):\n",
    "        date_str = local_date_string()\n",
    "        return ResearcherOutput(text=date_str, brief=True)\n",
    "\n",
    "    generator_prompt = (\n",
    "        \"You are a concise researcher. \"\n",
    "        \"Answer briefly (≤60 characters). \"\n",
    "        f\"User query: {query}\\nBrief answer:\"\n",
    "    )\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        gen_resp = call_gemini(generator_prompt).strip()\n",
    "        brief_flag = len(gen_resp) <= MAX_CHARS_BRIEF\n",
    "        out = ResearcherOutput(text=gen_resp, brief=brief_flag)\n",
    "\n",
    "        if brief_flag:\n",
    "            try:\n",
    "                out.validate_briefness()\n",
    "                return out\n",
    "            except ValidationError:\n",
    "                pass\n",
    "                critic_prompt = (\n",
    "            \"Rewrite this answer to be under 60 characters \"\n",
    "            \"and preserve only the essential fact.\\n\\n\"\n",
    "            f\"Answer:\\n{gen_resp}\\n\\nBrief rewrite:\"\n",
    "        )\n",
    "        rewrite = call_gemini(critic_prompt).strip()\n",
    "\n",
    "        if len(rewrite) <= MAX_CHARS_BRIEF:\n",
    "            return ResearcherOutput(text=rewrite, brief=True)\n",
    "        generator_prompt = (\n",
    "            f\"User query: {query}\\n\"\n",
    "            \"Give a one-line factual answer under 60 characters.\\nBrief answer:\"\n",
    "        )\n",
    "\n",
    "    truncated = out.text[:MAX_CHARS_BRIEF].rstrip(\" ,:;\")\n",
    "    return ResearcherOutput(text=truncated, brief=True)\n",
    "\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\nEnter your research query (type 'exit' to stop): \").strip()\n",
    "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"\\n Exiting Reflection Researcher. Goodbye!\\n\")\n",
    "        break\n",
    "\n",
    "    result = researcher_reflection(query)\n",
    "    print(f\"\\n AI is reflecting on your query...\\n\")\n",
    "    print(f\"Query: {query}\\n→ {result.text}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from google import genai\n",
    "\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyARvUEHkan-yQuL6Kfhy3XDFmG4Z6x_WP8\"\n",
    "\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "\n",
    "def reflect_query(query, brief=True):\n",
    "    q = query.lower().strip()\n",
    "\n",
    "    \n",
    "    if \"date\" in q:\n",
    "        today = datetime.datetime.now().strftime(\"%d.%m.%Y\")\n",
    "        return f\"→ {today} (brief={brief})\"\n",
    "\n",
    "    elif \"flight\" in q and \"kolkata\" in q and \"mumbai\" in q:\n",
    "        return f\"→ [LLM STUB] Reply to: User query: {query[:30]} (brief={brief})\"\n",
    "\n",
    "    elif \"weather\" in q and \"kolkata\" in q:\n",
    "        return f\"→ [LLM STUB] Reply to: User query: {query} (brief={brief})\"\n",
    "    else:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=f\"User query: {query}. Keep the answer brief={brief}.\"\n",
    "        )\n",
    "        return f\"→ {response.text}\"\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter your research query (type 'exit' to stop): \").strip()\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\" Reflection Researcher session ended.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n AI is reflecting on your query...\\n\")\n",
    "    answer = reflect_query(user_input)\n",
    "    print(f\"Query: {user_input}\\n{answer}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from google import genai\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyARvUEHkan-yQuL6Kfhy3XDFmG4Z6x_WP8\"\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "def reflect_query(query, brief=True):\n",
    "    q = query.lower().strip()\n",
    "\n",
    "    if \"date\" in q:\n",
    "        today = datetime.datetime.now().strftime(\"%d.%m.%Y\")\n",
    "        return f\"→ {today} (brief={brief})\"\n",
    "\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=f\"User query: {query}. Keep the answer brief={brief}.\"\n",
    "    )\n",
    "    return f\"→ {response.text}\"\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter your research query (type 'exit' to stop): \").strip()\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\" Reflection Researcher session ended.\")\n",
    "        break\n",
    "\n",
    "    print(\"\\n AI is reflecting on your query...\\n\")\n",
    "    answer = reflect_query(user_input)\n",
    "    print(f\"Query: {user_input}\\n{answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a50db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
