{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zVWw5RtuIle7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKOBewx5ImEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqMm2mkJIGAo",
        "outputId": "5ca2aba7-d0a1-4c6e-a0c1-cd99591b6622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.75)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.27)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting groq<1,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.3.8-py3-none-any.whl (16 kB)\n",
            "Downloading langchain_tavily-0.2.11-py3-none-any.whl (26 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, ormsgpack, mypy-extensions, marshmallow, typing-inspect, langgraph-sdk, groq, dataclasses-json, langgraph-checkpoint, langchain-groq, langgraph-prebuilt, langgraph, langchain-tavily, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 groq-0.31.1 langchain-community-0.3.29 langchain-groq-0.3.8 langchain-tavily-0.2.11 langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.10.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langgraph langchain-community langchain-groq langchain-tavily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f69e424",
        "outputId": "6d6dbfe5-6c6e-4a4d-ca4a-45d53bc36358"
      },
      "source": [
        "!pip uninstall -y requests\n",
        "!pip install requests==2.32.4\n",
        "!pip install tavily"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: requests 2.32.5\n",
            "Uninstalling requests-2.32.5:\n",
            "  Successfully uninstalled requests-2.32.5\n",
            "Collecting requests==2.32.4\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests==2.32.4) (2025.8.3)\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: requests\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.3.29 requires requests<3,>=2.32.5, but you have requests 2.32.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed requests-2.32.4\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tavily (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tavily\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tavily-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqs0zoQCNo-u",
        "outputId": "cc756a0a-96f0-4504-f994-20d4a4e6259a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tavily-python) (2.32.4)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.11.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tavily-python) (2025.8.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx->tavily-python) (4.15.0)\n",
            "Downloading tavily_python-0.7.12-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: tavily-python\n",
            "Successfully installed tavily-python-0.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage, AIMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from tavily import TavilyClient\n",
        "import os\n",
        "from groq import Groq"
      ],
      "metadata": {
        "id": "Zr2U4c6UIr_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
        "tavily = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
        "client = Groq(api_key=\"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\")"
      ],
      "metadata": {
        "id": "d12k9TVSIyP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_context = {}\n",
        "MAX_CLARIFICATIONS = 3"
      ],
      "metadata": {
        "id": "cyLqUYW2I1iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clarifier(user_question, user_context):\n",
        "    \"\"\"\n",
        "    Ask up to MAX_CLARIFICATIONS questions for any user query.\n",
        "    Returns either 'PROCEED' or a clarifying question string.\n",
        "    \"\"\"\n",
        "    clarifier_prompt = f\"\"\"\n",
        "You are a general-purpose question clarifier.\n",
        "Your job is to check if the user's question is missing any important detail\n",
        "that would help provide a precise and useful answer.\n",
        "\n",
        "Rules:\n",
        "- Ask **one clarifying question at a time**.\n",
        "- Be natural and conversational.\n",
        "- If the question is already clear enough, reply with 'PROCEED'.\n",
        "- Consider any context already provided: {user_context}\n",
        "\n",
        "User's question: \"{user_question}\"\n",
        "Clarifier:\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"system\", \"content\": clarifier_prompt}],\n",
        "        temperature=0.0\n",
        "    )\n",
        "    clarifier_text = response.choices[0].message.content.strip()\n",
        "    return clarifier_text"
      ],
      "metadata": {
        "id": "8oZ93-RkJJKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deep_search_node(state):\n",
        "    \"\"\"\n",
        "    Generate final answer from user's question after clarifications.\n",
        "    Limit query length to avoid Tavily errors.\n",
        "    \"\"\"\n",
        "    latest_question = state[\"messages\"][-1].content\n",
        "\n",
        "    # Combine essential context from user_context, not full user_question\n",
        "    context_text = \" \".join([f\"{k}: {v}\" for k, v in user_context.items()])\n",
        "    full_query = f\"{latest_question} {context_text}\".strip()\n",
        "\n",
        "    # Truncate to 400 chars to satisfy Tavily\n",
        "    if len(full_query) > 400:\n",
        "        full_query = full_query[-400:]  # take last 400 chars, usually latest info is more relevant\n",
        "\n",
        "    # Perform Tavily search\n",
        "    search_results = tavily.search(full_query, max_results=3)\n",
        "    results = search_results.get(\"results\", [])\n",
        "\n",
        "    formatted_results = []\n",
        "    for res in results:\n",
        "        if isinstance(res, dict):\n",
        "            url = res.get(\"url\", \"No URL\")\n",
        "            content = res.get(\"content\", \"\")[:500]\n",
        "            formatted_results.append(f\"Source: {url}\\nContent: {content}...\")\n",
        "        elif isinstance(res, str):\n",
        "            formatted_results.append(f\"Content: {res[:500]}...\")\n",
        "\n",
        "    if not formatted_results:\n",
        "        formatted_results.append(\"No results found.\")\n",
        "\n",
        "    return {\"messages\": [AIMessage(content=\"\\n\\n\".join(formatted_results))]}\n"
      ],
      "metadata": {
        "id": "V9zxMXqJJQyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatState(dict):\n",
        "    messages: list\n",
        "\n",
        "graph = StateGraph(ChatState)\n",
        "graph.add_node(\"answer\", deep_search_node)\n",
        "graph.set_entry_point(\"answer\")\n",
        "graph.add_edge(\"answer\", END)\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "P-2Uq7leJgE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# -------------------- Chat Loop --------------------\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"What's your question? (Type 'exit' to quit): \")\n",
        "    if user_question.lower() == \"exit\":\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    clarification_count = 0\n",
        "    # Clarification loop\n",
        "    while clarification_count < MAX_CLARIFICATIONS:\n",
        "        clarifier_msg = clarifier(user_question, user_context)\n",
        "        if clarifier_msg.strip().upper() == \"PROCEED\":\n",
        "            break\n",
        "        print(f\"Assistant: {clarifier_msg}\")\n",
        "        user_input = input(\"Your answer: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            break\n",
        "        # Dynamically store context info\n",
        "        user_context[clarifier_msg] = user_input\n",
        "        user_question += \" \" + user_input\n",
        "        clarification_count += 1\n",
        "\n",
        "    # Add user question to chat history\n",
        "    chat_history.append(HumanMessage(content=user_question))\n",
        "\n",
        "    # Call LangGraph node for final answer\n",
        "    for event in app.stream({\"messages\": chat_history}):\n",
        "        for value in event.values():\n",
        "            if value and isinstance(value.get(\"messages\"), list):\n",
        "                for msg in value[\"messages\"]:\n",
        "                    if isinstance(msg, AIMessage):\n",
        "                        print(\"\\nAssistant:\", msg.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIRPBgFqJWxw",
        "outputId": "7a8724a9-6c57-4518-ff40-b00e64bbf998"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: To help me narrow down the search, what type of location or area are you currently in?\n",
            "Assistant: So you're looking for a cafe in Bhubaneswar, Odisha. To give you the best possible recommendations, can you please tell me what part of Bhubaneswar you're currently in or would like to visit (like the Old Town or a specific area like Janpath or Patia)?\n",
            "Assistant: So you're looking for a cafe in Bhubaneswar, Odisha. To give you the best possible recommendations, can you please tell me what part of Bhubaneswar you're currently in or would like to visit (like the Old Town or a specific area like Janpath or Patia) in Patia?\n",
            "\n",
            "Assistant: Source: https://www.instagram.com/reel/DHlckjcP53R/?hl=en\n",
            "Content: Photo by Nutmeg | Bhubaneswar on September 19, 2025. May be an image of....\n",
            "\n",
            "Source: https://www.zomato.com/bhubaneswar/richards-kitchen-coffee-bar-patia-bhubaneshwar\n",
            "Content: Richard's Kitchen & Coffee Bar. Cafe, Chinese, Fast Food, Seafood, Sichuan. Plot A/2, 4th Floor, KIIT Square, Near Bata Showroom, Patia, Bhubaneshwar. Closed...\n",
            "\n",
            "Source: https://www.instagram.com/orioncafebbsr/?hl=en\n",
            "Content: Feeling on top of the world at our amazing rooftop cafe. ✆ Call/Whatsapp: 9776765008 Location: Plot No.- 516/4165 Kiit Square, near Biggies Burger, Patia,...\n",
            "Assistant: You're looking for a new laptop. To give you some good options, I'd like to ask: What's your approximate budget for the laptop?\n",
            "Assistant: To help me narrow down the options for you, can you please tell me what's your approximate budget for the laptop?\n",
            "Assistant: It seems like there might be a slight issue with the amount you mentioned. You said \"$600 dolars 600\". Are you referring to a total budget of $600 or is \"$600 dolars\" meant to represent one price, and you're looking at another specific laptop that's also around the same price point (which would be $600)?\n",
            "\n",
            "Assistant: Source: https://www.reddit.com/r/gamedev/comments/1hr463f/a_not_so_short_laptop_recommendation_guide_2025/\n",
            "Content: Figured that I have some time and it’s time to write an update to https://www.reddit.com/r/gamedev/comments/17ykkmu/a_not_so_short_laptop_purchasing_guide/ as it’s been over a year meaning that some changes have occured since. $550** - Acer Laptop Aspire 5 Intel Core i7-1355U - https://www.newegg.com/acer-a515-58m-78jl-15-6-intel-core-i7-1355u-16gb-intel-iris-xe-graphics-512-gb-pcie/p/N82E16834360267? We also get pretty much as good specs as you can in a laptop – 14700HX, 64GB RAM, 2TB SSD and a...\n",
            "\n",
            "Source: https://www.cnet.com/tech/computing/best-windows-laptop/\n",
            "Content: Best overall Windows laptop. Microsoft Surface Laptop 7 · $1,200 at Amazon ; Best budget laptop. Acer Aspire 14 AI · $500 at Costco ; Best laptop...\n",
            "\n",
            "Source: https://www.pcmag.com/picks/the-best-budget-laptops\n",
            "Content: Our current top cheap Windows laptop overall is the Acer Aspire 3, for its snappy processing, support for Wi-Fi 6, and long-lasting battery—all for less than...\n",
            "Assistant: It seems like your question might be a typo or unclear. Can you please clarify what you meant to ask?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ftD2AJSXJkH_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}