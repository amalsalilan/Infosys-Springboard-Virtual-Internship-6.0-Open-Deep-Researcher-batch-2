{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD9RcGudsBubyXUxK0kTJM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amalsalilan/Infosys-Springboard-Virtual-Internship-6.0-Open-Deep-Researcher-batch-2/blob/Prateek_Ray/calrifybot_researchberif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "umJjcTKGfiic",
        "outputId": "7499e46e-cf08-4790-beca-dda203c6db71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: google-generativeai 0.8.5\n",
            "Uninstalling google-generativeai-0.8.5:\n",
            "  Successfully uninstalled google-generativeai-0.8.5\n",
            "Found existing installation: google-ai-generativelanguage 0.7.0\n",
            "Uninstalling google-ai-generativelanguage-0.7.0:\n",
            "  Successfully uninstalled google-ai-generativelanguage-0.7.0\n",
            "Collecting google-generativeai==0.8.5\n",
            "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (2.25.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai==0.8.5) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai==0.8.5) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai==0.8.5) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.5) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.5) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai==0.8.5) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.5) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.5) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai==0.8.5) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai==0.8.5) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai==0.8.5) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai==0.8.5) (0.4.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai==0.8.5) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai==0.8.5) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.5) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.5) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.8.5) (2025.10.5)\n",
            "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.12 requires google-ai-generativelanguage<1,>=0.7, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "60415aa96dda49fda081375b85b1636c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.3.78)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.11.10)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.33)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.25.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.7.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "088225607aa24700a78b5cbec3ec64d2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y google-generativeai google-ai-generativelanguage\n",
        "!pip install google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15\n",
        "!pip install --upgrade langchain-google-genai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MAeOjcBgBeg",
        "outputId": "f9064b8c-28c7-490b-bb90-690b370abc4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.10-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.78)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.33)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.6.10-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.6.10 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = (\"YOUR_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = (\"YOUR_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"clarify-chatbot\"\n",
        "\n",
        "# Tavily (transport/search) API key — optional; if missing we will simulate results\n",
        "os.environ[\"TAVILY_API_KEY\"] = (\"YOUR_API_KEY\")\n",
        "\n",
        "MODEL_NAME = \"gemini-2.5-pro\"\n"
      ],
      "metadata": {
        "id": "0MAGxzlEFA2z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Optional, Dict, List\n",
        "import time, json, re, math, textwrap, datetime, requests, os\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Initialize LLM (keep deterministic for reproducibility)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
        "\n",
        "# Helper for safe text extraction\n",
        "def invoke_text(result):\n",
        "    if isinstance(result, dict):\n",
        "        return result.get(\"text\") or result.get(\"content\") or str(result)\n",
        "    return str(result)\n"
      ],
      "metadata": {
        "id": "pP4sZaSXgMiC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClarifyState(TypedDict):\n",
        "    query: str\n",
        "    missing_info: Optional[str]\n",
        "    clarification: Optional[str]\n",
        "    answer: Optional[str]\n",
        "    memory: Dict[str, str]\n",
        "\n",
        "# Analysis prompt\n",
        "analysis_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"memory_str\"],\n",
        "    template=\"\"\"\n",
        "User memory:\n",
        "{memory_str}\n",
        "\n",
        "Check if the user query needs a short clarification. If OK to answer, just say \"OK\".\n",
        "If more info is needed, reply exactly like this:\n",
        "CLARIFY: <what you need in 1 sentence>\n",
        "\n",
        "User query:\n",
        "{query}\n",
        "\"\"\"\n",
        ")\n",
        "analysis_chain = LLMChain(llm=llm, prompt=analysis_prompt)\n",
        "\n",
        "def analyze_node(state: ClarifyState):\n",
        "    memory_str = \"\\n\".join([f\"{k}: {v}\" for k,v in state.get(\"memory\", {}).items()])\n",
        "    raw = analysis_chain.invoke({\"query\": state.get(\"query\",\"\"), \"memory_str\": memory_str})\n",
        "    raw_text = invoke_text(raw).strip()\n",
        "    if raw_text.upper().startswith(\"CLARIFY:\"):\n",
        "        state[\"missing_info\"] = raw_text.split(\"CLARIFY:\",1)[1].strip()\n",
        "    else:\n",
        "        state[\"missing_info\"] = None\n",
        "    return state\n",
        "\n",
        "def clarify_node(state: ClarifyState):\n",
        "    missing = state.get(\"missing_info\")\n",
        "    if missing:\n",
        "        print(\"Bot:\", f\"Can you clarify: {missing}?\")\n",
        "        user_ans = input(\"You (clarification): \").strip()\n",
        "        if user_ans.lower() in (\"exit\",\"quit\"):\n",
        "            print(\"Goodbye!\")\n",
        "            raise SystemExit()\n",
        "        state[\"clarification\"] = user_ans\n",
        "        # quick memory extraction heuristics\n",
        "        lower = user_ans.lower()\n",
        "        if \"my name is\" in lower:\n",
        "            name = re.split(r\"my name is\", lower, 1)[1].strip().split()[0].title()\n",
        "            state[\"memory\"][\"name\"] = name\n",
        "        elif \"i live in\" in lower or \"my city is\" in lower:\n",
        "            city = re.sub(r\"(i live in|my city is)\", \"\", lower).strip().title()\n",
        "            state[\"memory\"][\"city\"] = city\n",
        "        else:\n",
        "            key = missing.replace(\" \", \"_\").lower()\n",
        "            state[\"memory\"][key] = user_ans\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "03UlOB6DgOvZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_memory_from_text(text: str, memory: dict) -> dict:\n",
        "    lower = text.lower()\n",
        "    new_memory = memory.copy()\n",
        "    m = re.search(r\"\\bmy name is (\\w+)\", lower)\n",
        "    if m: new_memory[\"name\"] = m.group(1).title()\n",
        "    m = re.search(r\"\\bi live in ([a-z\\s]+)\", lower)\n",
        "    if m: new_memory[\"city\"] = m.group(1).title()\n",
        "    m = re.search(r\"\\bfrom ([a-z\\s]+) to ([a-z\\s]+)\", lower)\n",
        "    if m:\n",
        "        new_memory[\"origin\"] = m.group(1).title()\n",
        "        new_memory[\"destination\"] = m.group(2).title()\n",
        "    m = re.search(r\"(\\d+[,\\d]*)\\s*(inr|usd|rs|rupees|₹)\", lower)\n",
        "    if m: new_memory[\"budget\"] = m.group(1)\n",
        "    m = re.search(r\"\\b(\\d{1,2}\\s+\\w+\\s*\\d{4}?)\", text)\n",
        "    if m: new_memory[\"date\"] = m.group(1)\n",
        "    return new_memory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "duY19ZtdhSco"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_KEY = os.environ.get(\"TAVILY_API_KEY\") or \"\"\n",
        "\n",
        "def tavily_search(query: str, location: Optional[str]=None, budget: Optional[str]=None, limit=5):\n",
        "    \"\"\"\n",
        "    Query Tavily if key present, otherwise return simulated results.\n",
        "    Expected return: list of dicts with keys: title, url, snippet, price\n",
        "    \"\"\"\n",
        "    if not TAVILY_KEY:\n",
        "        # Simulated results for dev when API not available\n",
        "        simulated = [\n",
        "            {\"title\":\"Sample Flight - Airline A\", \"url\":\"https://example.com/flightA\", \"snippet\":\"one-stop via place\", \"price\":\"₹80,000\"},\n",
        "            {\"title\":\"Sample Hotel - Budget Inn\", \"url\":\"https://example.com/hotel1\", \"snippet\":\"3-star near Strip\", \"price\":\"₹6,000/night\"},\n",
        "            {\"title\":\"Sample Train/Bus Option\", \"url\":\"https://example.com/train\", \"snippet\":\"connect via hub\", \"price\":\"₹5,000\"}\n",
        "        ]\n",
        "        return simulated[:limit]\n",
        "    # Real Tavily call — adapt to Tavily API docs\n",
        "    headers = {\"Authorization\": f\"Bearer {TAVILY_KEY}\", \"Content-Type\":\"application/json\"}\n",
        "    payload = {\"q\": query, \"location\": location, \"budget\": budget, \"limit\": limit}\n",
        "    try:\n",
        "        resp = requests.post(\"https://api.tavily.com/v1/search\", headers=headers, json=payload, timeout=15)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        # map to expected shape (depends on API output)\n",
        "        results = []\n",
        "        for item in data.get(\"results\", [])[:limit]:\n",
        "            results.append({\n",
        "                \"title\": item.get(\"title\"),\n",
        "                \"url\": item.get(\"url\"),\n",
        "                \"snippet\": item.get(\"snippet\") or item.get(\"description\", \"\"),\n",
        "                \"price\": item.get(\"price\")\n",
        "            })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(\"Tavily search failed:\", e)\n",
        "        # fallback to empty list\n",
        "        return []\n",
        "\n",
        "def run_deep_research(query: str, origin: Optional[str]=None, budget: Optional[str]=None):\n",
        "    # 1) gather raw results\n",
        "    flights = tavily_search(f\"{query} cheapest flights {origin or ''}\", limit=5)\n",
        "    hotels = tavily_search(f\"{query} hotels stays {origin or ''}\", limit=5)\n",
        "    activities = tavily_search(f\"{query} things to do {origin or ''}\", limit=5)\n",
        "\n",
        "    # Add static URLs for top flight aggregators and hotels\n",
        "    flight_links = [\n",
        "        {\"title\":\"Skyscanner\", \"url\":\"https://www.skyscanner.co.in\"},\n",
        "        {\"title\":\"Kayak\", \"url\":\"https://www.kayak.co.in\"},\n",
        "        {\"title\":\"Google Flights\", \"url\":\"https://www.google.com/flights\"}\n",
        "    ]\n",
        "    hotel_links = [\n",
        "        {\"title\":\"Booking.com\", \"url\":\"https://www.booking.com\"},\n",
        "        {\"title\":\"Agoda\", \"url\":\"https://www.agoda.com\"},\n",
        "        {\"title\":\"Rove Hotels\", \"url\":\"https://www.rovehotels.com\"}\n",
        "    ]\n",
        "\n",
        "    # Merge static links into flights/hotels JSON so LLM sees them\n",
        "    flights_json = json.dumps(flights + flight_links, ensure_ascii=False)\n",
        "    hotels_json = json.dumps(hotels + hotel_links, ensure_ascii=False)\n",
        "    activities_json = json.dumps(activities, ensure_ascii=False)\n",
        "    today = datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n",
        "\n",
        "    # LLM prompt\n",
        "    synth_prompt = PromptTemplate(\n",
        "        input_variables=[\"query\",\"origin\",\"budget\",\"flights\",\"hotels\",\"activities\",\"today\"],\n",
        "        template=\"\"\"\n",
        "You are an expert travel researcher. Using the raw results below, produce a travel research brief.\n",
        "Include:\n",
        "1) One-paragraph executive summary.\n",
        "2) A compact table of the top 3 transport options with cost and boarding/offboarding details and source URL (CSV-style).\n",
        "3) Top 3 hotel/stay picks (name, nightly, area, booking URL).\n",
        "4) 5 bullet-point practical tips (visa, transit time, cheapest booking tips).\n",
        "5) List of source URLs.\n",
        "\n",
        "Flights raw:\n",
        "{flights}\n",
        "\n",
        "Hotels raw:\n",
        "{hotels}\n",
        "\n",
        "Activities raw:\n",
        "{activities}\n",
        "\n",
        "Origin: {origin}\n",
        "Budget: {budget}\n",
        "Query: {query}\n",
        "Date produced: {today}\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    synth_chain = LLMChain(llm=llm, prompt=synth_prompt)\n",
        "    prompt_vars = {\n",
        "        \"query\": query,\n",
        "        \"origin\": origin or \"\",\n",
        "        \"budget\": budget or \"\",\n",
        "        \"flights\": flights_json,\n",
        "        \"hotels\": hotels_json,\n",
        "        \"activities\": activities_json,\n",
        "        \"today\": today\n",
        "    }\n",
        "    response = synth_chain.invoke(prompt_vars)\n",
        "    brief_text = invoke_text(response)\n",
        "\n",
        "    # create simple table structure from the top items (best-effort)\n",
        "    table = []\n",
        "    sources = [f[\"url\"] for f in flight_links + hotel_links]  # start with static URLs\n",
        "    for s in (flights[:3] + hotels[:3] + activities[:3]):\n",
        "        url = s.get(\"url\")\n",
        "        if url: sources.append(url)\n",
        "\n",
        "    return {\"brief\": brief_text, \"table\": table, \"sources\": list(dict.fromkeys(sources))}\n"
      ],
      "metadata": {
        "id": "dLWyQJTKhZBh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_text_from_llm_chain(chain: LLMChain, inputs: dict, chunk_size=80, delay=0.02):\n",
        "    try:\n",
        "        if hasattr(chain, \"stream\") and callable(chain.stream):\n",
        "            tokens = []\n",
        "            for token_chunk in chain.stream(inputs):\n",
        "                t = token_chunk.get(\"text\") if isinstance(token_chunk, dict) else str(token_chunk)\n",
        "                print(t, end=\"\", flush=True)\n",
        "                tokens.append(t)\n",
        "            print()\n",
        "            return \"\".join(tokens)\n",
        "    except Exception:\n",
        "        pass\n",
        "    res = chain.invoke(inputs)\n",
        "    text = invoke_text(res)\n",
        "    for i in range(0, len(text), chunk_size):\n",
        "        print(text[i:i+chunk_size], end=\"\", flush=True)\n",
        "        time.sleep(delay)\n",
        "    print()\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "E5nM35sLha6S"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_node(state: ClarifyState):\n",
        "    clarification = state.get(\"clarification\") or \"\"\n",
        "    memory_str = \"\\n\".join([f\"{k}: {v}\" for k,v in state.get(\"memory\", {}).items()])\n",
        "\n",
        "    # Determine whether deep research is required\n",
        "    run_text = stream_text_from_llm_chain(answer_chain, {\n",
        "        \"query\": state[\"query\"],\n",
        "        \"clarification\": clarification,\n",
        "        \"memory_str\": memory_str\n",
        "    }, chunk_size=120, delay=0.01)\n",
        "\n",
        "    run_text_stripped = (run_text or \"\").strip()\n",
        "\n",
        "    if run_text_stripped == \"DEEP_RESEARCH_NEEDED\":\n",
        "        # parse origin & budget from memory or query/clarification\n",
        "        origin = state[\"memory\"].get(\"city\") or state[\"memory\"].get(\"origin\") or None\n",
        "        budget = None\n",
        "        m = re.search(r\"(\\d+[,\\d]*)\\s*(inr|usd|rs|rupees|₹)?\", state[\"query\"].lower())\n",
        "        if m:\n",
        "            budget = m.group(1)\n",
        "\n",
        "        # run deep research\n",
        "        research = run_deep_research(state[\"query\"], origin=origin, budget=budget)\n",
        "        brief_text = research.get(\"brief\", \"No research data available.\")\n",
        "        state[\"answer\"] = brief_text\n",
        "\n",
        "        # stream the brief token-by-token\n",
        "        print(\"\\n--- Research Brief ---\")\n",
        "        for i in range(0, len(brief_text), 120):\n",
        "            print(brief_text[i:i+120], end=\"\", flush=True)\n",
        "            time.sleep(0.02)\n",
        "        print(\"\\n--- Sources ---\")\n",
        "        for s in research.get(\"sources\", []):\n",
        "            print(\"-\", s)\n",
        "    else:\n",
        "        state[\"answer\"] = run_text or \"No answer generated.\"\n",
        "\n",
        "    # quick memory extraction from answer\n",
        "    update_memory_from_text(state[\"answer\"] or \"\", state[\"memory\"])\n",
        "    print()  # newline\n",
        "    return state\n",
        "\n"
      ],
      "metadata": {
        "id": "RG4kr8k_hdHX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reflection_node(state: ClarifyState):\n",
        "    \"\"\"\n",
        "    Evaluates the answer for completeness, accuracy, and relevance.\n",
        "    Assigns a quality score (0-100) and improvement suggestions.\n",
        "    \"\"\"\n",
        "    content = state.get(\"answer\") or \"No content to reflect on.\"\n",
        "\n",
        "    reflection_prompt = PromptTemplate(\n",
        "        input_variables=[\"content\"],\n",
        "        template=\"\"\"\n",
        "You are a travel content evaluator. Evaluate the provided research report for:\n",
        "1) Completeness (flights, hotels, activities)\n",
        "2) Accuracy (budget, dates)\n",
        "3) Usefulness and clarity for the user\n",
        "\n",
        "Score the content 0-100.\n",
        "If below 80, provide brief suggestions to improve.\n",
        "\n",
        "Content:\n",
        "{content}\n",
        "\"\"\"\n",
        "    )\n",
        "    reflection_chain = LLMChain(llm=llm, prompt=reflection_prompt)\n",
        "\n",
        "    reflection_text = stream_text_from_llm_chain(reflection_chain, {\"content\": content}, chunk_size=80, delay=0.01)\n",
        "    reflection_text = reflection_text.strip()\n",
        "\n",
        "    # Extract score and suggestions (simple parsing)\n",
        "    score_match = re.search(r\"(\\d{1,3})\", reflection_text)\n",
        "    score = int(score_match.group(1)) if score_match else 1\n",
        "    status = \"OK\" if score >= 80 else \"IMPROVE\"\n",
        "\n",
        "    # Extract improvement suggestions if score < 80\n",
        "    suggestions_match = re.search(r\"(?:suggestions?:\\s*)(.+)\", reflection_text, re.IGNORECASE | re.DOTALL)\n",
        "    suggestions = suggestions_match.group(1).strip() if suggestions_match else \"\"\n",
        "\n",
        "    state[\"reflection_score\"] = score\n",
        "    state[\"quality_score\"] = score\n",
        "    state[\"reflection_status\"] = status\n",
        "    state[\"improvement_suggestions\"] = suggestions\n",
        "\n",
        "    print(f\"\\nReflection result: Score = {score}/100, Status = {status}\")\n",
        "    if suggestions:\n",
        "        print(\"Improvement suggestions:\", suggestions)\n",
        "    return state\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b8FE9ZLphgww"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(ClarifyState)\n",
        "workflow.add_node(\"analyze\", analyze_node)\n",
        "workflow.add_node(\"clarify\", clarify_node)\n",
        "workflow.add_node(\"answer\", answer_node)\n",
        "workflow.set_entry_point(\"analyze\")\n",
        "workflow.add_conditional_edges(\"analyze\", lambda s: \"clarify\" if s.get(\"missing_info\") else \"answer\",\n",
        "                               {\"clarify\":\"clarify\",\"answer\":\"answer\"})\n",
        "workflow.add_edge(\"clarify\",\"answer\")\n",
        "workflow.add_edge(\"answer\", END)\n",
        "app = workflow.compile()\n",
        "\n",
        "def clarify_with_user_memory():\n",
        "    print(\"Type 'exit' to quit.\\n\")\n",
        "    memory_dict: Dict[str,str] = {}\n",
        "    followups: List[str] = []\n",
        "\n",
        "    while True:\n",
        "        # choose input prompt depending on whether followups shown previously\n",
        "        if followups:\n",
        "            user_input = input(\"You (or choose 1/2/3): \").strip()\n",
        "            # if user typed a digit, select followup\n",
        "            if user_input.isdigit():\n",
        "                idx = int(user_input)\n",
        "                if 1 <= idx <= len(followups):\n",
        "                    user_input = followups[idx-1]\n",
        "                    print(f\"You selected follow-up: {user_input}\")\n",
        "        else:\n",
        "            user_input = input(\"You: \").strip()\n",
        "\n",
        "        if user_input.lower() in (\"exit\",\"quit\"):\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # update memory heuristics immediately with user-provided facts\n",
        "        memory_dict = update_memory_from_text(user_input, memory_dict)\n",
        "\n",
        "        # build state\n",
        "        state: ClarifyState = {\n",
        "            \"query\": user_input,\n",
        "            \"missing_info\": None,\n",
        "            \"clarification\": \"\",\n",
        "            \"answer\": None,\n",
        "            \"memory\": memory_dict\n",
        "        }\n",
        "\n",
        "        # run graph\n",
        "        final_state = app.invoke(state)\n",
        "        if isinstance(final_state, dict):\n",
        "            final_state = final_state\n",
        "\n",
        "        # safe memory update\n",
        "        memory_dict.update(final_state.get(\"memory\", {}))\n",
        "        memory_dict = update_memory_from_text(final_state.get(\"answer\",\"\") or \"\", memory_dict)\n",
        "\n",
        "        # reflection-based regeneration loop\n",
        "        # only regenerate if reflection_status == \"IMPROVE\" AND score < 90\n",
        "        while final_state.get(\"reflection_status\") == \"IMPROVE\" and (final_state.get(\"quality_score\") or 0) < 90:\n",
        "            print(\"\\nRegenerating content based on reflection suggestions...\")\n",
        "            improvement_note = final_state.get(\"improvement_suggestions\") or \"\"\n",
        "            state[\"clarification\"] = ((state.get(\"clarification\") or \"\") + \" \" + improvement_note).strip()\n",
        "            final_state = answer_node(state)\n",
        "            final_state = reflection_node(final_state)\n",
        "            # update memory again after regeneration\n",
        "            memory_dict.update(final_state.get(\"memory\", {}))\n",
        "            memory_dict = update_memory_from_text(final_state.get(\"answer\",\"\") or \"\", memory_dict)\n",
        "\n",
        "        # show followups\n",
        "        followups = suggest_followups(final_state.get(\"answer\",\"\") or \"\")\n",
        "        if followups:\n",
        "            print(\"\\nPossible follow-ups:\")\n",
        "            for i,s in enumerate(followups,1):\n",
        "                print(f\"{i}. {s}\")\n",
        "\n",
        "        # display reflection and quality score\n",
        "        print(f\"\\nReflection result: Score = {final_state.get('quality_score',0)}/100, Status = {final_state.get('reflection_status','UNKNOWN')}\")\n",
        "        print(\"\\n=== Final Research Report / Answer ===\")\n",
        "        print(final_state.get(\"answer\",\"None\"))\n",
        "        print(f\"\\nQuality Score: {final_state.get('quality_score',0)}/100\")\n",
        "\n",
        "        # debugging memory\n",
        "        print(\"Current memory:\", memory_dict)\n",
        "        print(\"-\"*40)\n"
      ],
      "metadata": {
        "id": "aviKk1cehh3n"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clarify_with_user_memory()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mfH9ZhohpG4",
        "outputId": "c9841338-152f-4cb3-a008-8da5c562aedf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 'exit' to quit.\n",
            "\n",
            "You: make a round trip plan of 1 week from delhi to dubai on 01-11-2025. it will be a solo trip and budget will 1 lakh and suggest cheap flights and stays\n",
            "DEEP_RESEARCH_NEEDED\n",
            "Tavily search failed: 404 Client Error: Not Found for url: https://api.tavily.com/v1/search\n",
            "Tavily search failed: 404 Client Error: Not Found for url: https://api.tavily.com/v1/search\n",
            "Tavily search failed: 404 Client Error: Not Found for url: https://api.tavily.com/v1/search\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3145850897.py:60: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  today = datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M UTC\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Research Brief ---\n",
            "Of course. Here is the travel research brief based on your request.\n",
            "\n",
            "***\n",
            "\n",
            "### **Travel Research Brief: Delhi to Dubai**\n",
            "\n",
            "**1. Executive Summary**\n",
            "\n",
            "This brief outlines a one-week solo trip from Delhi to Dubai from November 1-8, 2025, with a total budget of ₹1,00,000. The plan is highly feasible, focusing on cost-effective travel and accommodation. The core recommendation is to book flights on budget carriers like IndiGo or SpiceJet approximately 4-6 months in advance for optimal pricing, estimated at ₹20,000-₹25,000. For accommodation, staying in well-connected, budget-friendly areas like Deira or Bur Dubai is advised, with recommended hotels averaging ₹5,500-₹7,000 per night. This strategy leaves a substantial portion of the budget for activities, food, and local transport, ensuring a comfortable and comprehensive travel experience.\n",
            "\n",
            "**2. Top 3 Transport Options**\n",
            "\n",
            "| Option | Est. Round-Trip Cost (INR) | Boarding/Offboarding | Source |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| Budget Airline Comparison | ₹20,000 - ₹25,000 | Delhi (DEL) / Dubai (DXB) | https://www.skyscanner.co.in |\n",
            "| Flight Deal Aggregator | ₹20,000 - ₹25,000 | Delhi (DEL) / Dubai (DXB) | https://www.google.com/flights |\n",
            "| Alternative Flight Search | ₹21,000 - ₹26,000 | Delhi (DEL) / Dubai (DXB) | https://www.kayak.co.in |\n",
            "\n",
            "**3. Top 3 Hotel/Stay Picks**\n",
            "\n",
            "| Hotel Name | Est. Nightly Rate (INR) | Area | Booking URL |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| Rove City Centre | ₹7,000 | Deira | https://www.rovehotels.com |\n",
            "| Ibis Al Rigga | ₹5,500 | Deira | https://www.booking.com |\n",
            "| Golden Sands Hotel Apartments | ₹6,000 | Bur Dubai | https://www.agoda.com |\n",
            "\n",
            "**4. Practical Tips**\n",
            "\n",
            "*   **Visa:** As an Indian passport holder, you will need a pre-arranged UAE visa. You can apply for a 30-day tourist e-visa online through airlines like Emirates or VFS Global. Start this process at least one month before your travel date.\n",
            "*   **Airport Transit:** Dubai International Airport (DXB) is efficiently connected to the city via the Dubai Metro. A trip from Terminal 1 or 3 to Deira or Bur Dubai takes approximately 15-25 minutes and is the most economical option.\n",
            "*   **Cheapest Flight Booking:** For the best prices, book your round-trip flight 4-6 months in advance. Use the aggregator sites to set price alerts and consider flying on a weekday (Tuesday or Wednesday) as fares are often lower.\n",
            "*   **Affordable Stays:** Look for hotels in Deira and Bur Dubai. These older parts of the city offer excellent value, are hubs for cheap and delicious food, and have great metro connectivity to major attractions like the Dubai Mall and Burj Khalifa.\n",
            "*   **Local Transport & Currency:** Purchase a Nol card at any metro station upon arrival. This rechargeable card is your key to using the metro, buses, and trams affordably. The local currency is the UAE Dirham (AED); it's best to exchange a small amount at the airport and the rest at a currency exchange in the city for better rates.\n",
            "\n",
            "**5. Source URLs**\n",
            "\n",
            "*   https://www.skyscanner.co.in\n",
            "*   https://www.kayak.co.in\n",
            "*   https://www.google.com/flights\n",
            "*   https://www.booking.com\n",
            "*   https://www.agoda.com\n",
            "*   https://www.rovehotels.com\n",
            "--- Sources ---\n",
            "- https://www.skyscanner.co.in\n",
            "- https://www.kayak.co.in\n",
            "- https://www.google.com/flights\n",
            "- https://www.booking.com\n",
            "- https://www.agoda.com\n",
            "- https://www.rovehotels.com\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
            "Please retry in 14.532861571s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 2\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 14\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
            "Please retry in 12.490290246s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 2\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 12\n",
            "}\n",
            "].\n",
            "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
            "Please retry in 8.44436065s. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.5-pro\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 2\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 8\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Possible follow-ups:\n",
            "1. Based on the answer provided, here are 3 short follow-up questions:\n",
            "2. Can you suggest a 7-day itinerary that balances major attractions with budget-friendly activities?\n",
            "3. How would you break down the remaining budget for daily expenses like food, local transport, and attraction tickets?\n",
            "\n",
            "Reflection result: Score = 0/100, Status = UNKNOWN\n",
            "\n",
            "=== Final Research Report / Answer ===\n",
            "Of course. Here is the travel research brief based on your request.\n",
            "\n",
            "***\n",
            "\n",
            "### **Travel Research Brief: Delhi to Dubai**\n",
            "\n",
            "**1. Executive Summary**\n",
            "\n",
            "This brief outlines a one-week solo trip from Delhi to Dubai from November 1-8, 2025, with a total budget of ₹1,00,000. The plan is highly feasible, focusing on cost-effective travel and accommodation. The core recommendation is to book flights on budget carriers like IndiGo or SpiceJet approximately 4-6 months in advance for optimal pricing, estimated at ₹20,000-₹25,000. For accommodation, staying in well-connected, budget-friendly areas like Deira or Bur Dubai is advised, with recommended hotels averaging ₹5,500-₹7,000 per night. This strategy leaves a substantial portion of the budget for activities, food, and local transport, ensuring a comfortable and comprehensive travel experience.\n",
            "\n",
            "**2. Top 3 Transport Options**\n",
            "\n",
            "| Option | Est. Round-Trip Cost (INR) | Boarding/Offboarding | Source |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| Budget Airline Comparison | ₹20,000 - ₹25,000 | Delhi (DEL) / Dubai (DXB) | https://www.skyscanner.co.in |\n",
            "| Flight Deal Aggregator | ₹20,000 - ₹25,000 | Delhi (DEL) / Dubai (DXB) | https://www.google.com/flights |\n",
            "| Alternative Flight Search | ₹21,000 - ₹26,000 | Delhi (DEL) / Dubai (DXB) | https://www.kayak.co.in |\n",
            "\n",
            "**3. Top 3 Hotel/Stay Picks**\n",
            "\n",
            "| Hotel Name | Est. Nightly Rate (INR) | Area | Booking URL |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| Rove City Centre | ₹7,000 | Deira | https://www.rovehotels.com |\n",
            "| Ibis Al Rigga | ₹5,500 | Deira | https://www.booking.com |\n",
            "| Golden Sands Hotel Apartments | ₹6,000 | Bur Dubai | https://www.agoda.com |\n",
            "\n",
            "**4. Practical Tips**\n",
            "\n",
            "*   **Visa:** As an Indian passport holder, you will need a pre-arranged UAE visa. You can apply for a 30-day tourist e-visa online through airlines like Emirates or VFS Global. Start this process at least one month before your travel date.\n",
            "*   **Airport Transit:** Dubai International Airport (DXB) is efficiently connected to the city via the Dubai Metro. A trip from Terminal 1 or 3 to Deira or Bur Dubai takes approximately 15-25 minutes and is the most economical option.\n",
            "*   **Cheapest Flight Booking:** For the best prices, book your round-trip flight 4-6 months in advance. Use the aggregator sites to set price alerts and consider flying on a weekday (Tuesday or Wednesday) as fares are often lower.\n",
            "*   **Affordable Stays:** Look for hotels in Deira and Bur Dubai. These older parts of the city offer excellent value, are hubs for cheap and delicious food, and have great metro connectivity to major attractions like the Dubai Mall and Burj Khalifa.\n",
            "*   **Local Transport & Currency:** Purchase a Nol card at any metro station upon arrival. This rechargeable card is your key to using the metro, buses, and trams affordably. The local currency is the UAE Dirham (AED); it's best to exchange a small amount at the airport and the rest at a currency exchange in the city for better rates.\n",
            "\n",
            "**5. Source URLs**\n",
            "\n",
            "*   https://www.skyscanner.co.in\n",
            "*   https://www.kayak.co.in\n",
            "*   https://www.google.com/flights\n",
            "*   https://www.booking.com\n",
            "*   https://www.agoda.com\n",
            "*   https://www.rovehotels.com\n",
            "\n",
            "Quality Score: 0/100\n",
            "Current memory: {'origin': 'Delhi', 'destination': 'Dubai From November '}\n",
            "----------------------------------------\n",
            "You (or choose 1/2/3): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}