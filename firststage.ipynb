{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai\n",
        "\n",
        "import os\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "\n",
        "class InteractiveResearchClarifier:\n",
        "    def __init__(self, api_key, max_tokens=8000):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.current_tokens = 0\n",
        "        self.max_iterations = 5 #5 is a limit set by me for reserving tokens for more research , can be changed if wanted\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel('gemini-1.5-flash') #less tokens will be used , please use gemini 1.5 models.\n",
        "\n",
        "    def estimate_tokens(self, text):\n",
        "        return len(text.split()) * 1.3\n",
        "\n",
        "    def check_token_balance(self, additional_tokens):\n",
        "        return (self.current_tokens + additional_tokens) < self.max_tokens\n",
        "\n",
        "    def analyze_query_sufficiency(self, conversation_context):\n",
        "        prompt_tokens = self.estimate_tokens(conversation_context)\n",
        "\n",
        "        if not self.check_token_balance(prompt_tokens):\n",
        "            return {\"status\": \"insufficient_tokens\"}\n",
        "\n",
        "        analysis_prompt = f\"\"\"\n",
        "Analyze this research conversation: \"{conversation_context}\"\n",
        "\n",
        "Determine if there is now enough information to start research or if more clarification is needed.\n",
        "\n",
        "Consider the original query and all follow-up answers provided.\n",
        "\n",
        "Respond in exact JSON format:\n",
        "{{\n",
        "    \"sufficient_for_research\": true or false,\n",
        "    \"research_topic\": \"brief summary of what will be researched\",\n",
        "    \"follow_up_questions\": [\"specific question 1\", \"specific question 2\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.model.generate_content(analysis_prompt)\n",
        "            self.current_tokens += prompt_tokens\n",
        "\n",
        "            response_text = response.text.strip()\n",
        "\n",
        "            if \"json\" in response_text:\n",
        "                lines = response_text.split('\\n')\n",
        "                json_lines = []\n",
        "                capture = False\n",
        "                for line in lines:\n",
        "                    if line.strip().startswith('{'):\n",
        "                        capture = True\n",
        "                    if capture:\n",
        "                        json_lines.append(line)\n",
        "                    if line.strip().endswith('}'):\n",
        "                        break\n",
        "                response_text = '\\n'.join(json_lines)\n",
        "\n",
        "            result = json.loads(response_text)\n",
        "\n",
        "            if \"sufficient_for_research\" not in result:\n",
        "                result[\"sufficient_for_research\"] = False\n",
        "                result[\"follow_up_questions\"] = [\"Could you provide more details?\"]\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception:\n",
        "            return {\n",
        "                \"sufficient_for_research\": False,\n",
        "                \"research_topic\": \"\",\n",
        "                \"follow_up_questions\": [\"Could you provide more specific details?\"]\n",
        "            }\n",
        "\n",
        "    def interactive_research_clarification(self):\n",
        "        if not self.check_token_balance(100):\n",
        "            print(\"Insufficient token balance to process requests.\")\n",
        "            return\n",
        "\n",
        "        print(\"What do you want to research?\")\n",
        "        initial_query = input().strip()\n",
        "\n",
        "        if not initial_query:\n",
        "            print(\"Please provide a valid research query.\")\n",
        "            return\n",
        "\n",
        "        conversation_context = f\"Original query: {initial_query}\"\n",
        "        iteration = 0\n",
        "\n",
        "        while iteration < self.max_iterations:\n",
        "            print(f\"\\n- Analysis Round {iteration + 1} -\")\n",
        "\n",
        "            analysis = self.analyze_query_sufficiency(conversation_context)\n",
        "\n",
        "            if \"status\" in analysis and analysis[\"status\"] == \"insufficient_tokens\":\n",
        "                print(\"Insufficient token balance for this query.\")\n",
        "                break\n",
        "\n",
        "            if analysis[\"sufficient_for_research\"]:\n",
        "                print(\"\\n SUCCESS: Your query is now sufficient for research!\")\n",
        "                print(f\" Research Topic: {analysis['research_topic']}\")\n",
        "                print(\"\\n Let's start the research phase!\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"\\n More information needed:\")\n",
        "                questions = analysis.get(\"follow_up_questions\", [])\n",
        "\n",
        "                if not questions:\n",
        "                    print(\"No specific questions generated. Please provide more details about your research needs.\")\n",
        "                    additional_info = input(\"Additional information: \").strip()\n",
        "                    if additional_info:\n",
        "                        conversation_context += f\" Additional info: {additional_info}\"\n",
        "                else:\n",
        "                    for i, question in enumerate(questions, 1):\n",
        "                        print(f\"{i}. {question}\")\n",
        "\n",
        "                    print(f\"\\nPlease answer question 1:\")\n",
        "                    answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                    if answer:\n",
        "                        conversation_context += f\" Answer to '{questions[0]}': {answer}\"\n",
        "                    else:\n",
        "                        print(\"No answer provided. Ending clarification process.\")\n",
        "                        break\n",
        "\n",
        "            iteration += 1\n",
        "\n",
        "        if iteration >= self.max_iterations:\n",
        "            print(f\"\\n Maximum clarification rounds ({self.max_iterations}) reached.\")\n",
        "            print(\"Proceeding with available information:\")\n",
        "            print(f\" Research Context: {conversation_context}\")\n",
        "            print(\"\\n Starting research phase with current information!\")\n",
        "\n",
        "    def quick_test(self):\n",
        "        test_queries = [\n",
        "            \"What are the best ways to travel from Mumbai to Goa?\",\n",
        "            \"Research about AI\",\n",
        "            \"Is Ayush better than AI?\",\n",
        "            \"Compare programming languages\"\n",
        "        ]\n",
        "\n",
        "        print(\" Quick Test Mode - Testing different query types:\\n\")\n",
        "\n",
        "        for i, query in enumerate(test_queries, 1):\n",
        "            print(f\"Test {i}: {query}\")\n",
        "            analysis = self.analyze_query_sufficiency(f\"Original query: {query}\")\n",
        "\n",
        "            if analysis[\"sufficient_for_research\"]:\n",
        "                print(f\" Sufficient - Topic: {analysis['research_topic']}\")\n",
        "            else:\n",
        "                print(f\" Needs clarification:\")\n",
        "                for j, q in enumerate(analysis[\"follow_up_questions\"], 1):\n",
        "                    print(f\"   {j}. {q}\")\n",
        "            print()\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] = 'Insert your gemini api key here'\n",
        "\n",
        "clarifier = InteractiveResearchClarifier(os.environ['GEMINI_API_KEY'])\n",
        "\n",
        "print(\" Interactive deepresearcher firststage:\")\n",
        "print(\"Choose mode:\")\n",
        "print(\"1. Interactive Mode (Full clarification process)\")\n",
        "print(\"2. Quick Test Mode (Test different query types)\")\n",
        "\n",
        "choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "if choice == \"1\":\n",
        "    clarifier.interactive_research_clarification()\n",
        "elif choice == \"2\":\n",
        "    clarifier.quick_test()\n",
        "else:\n",
        "    print(\"Invalid choice. Starting interactive mode by default.\")\n",
        "    clarifier.interactive_research_clarification()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MaQOfm7sxUAN",
        "outputId": "7b8e696b-a943-4681-d41b-4ef920768035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.181.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
            "🔬 INTERACTIVE RESEARCH CLARIFIER\n",
            "Choose mode:\n",
            "1. Interactive Mode (Full clarification process)\n",
            "2. Quick Test Mode (Test different query types)\n",
            "Enter 1 or 2: 2\n",
            "🧪 Quick Test Mode - Testing different query types:\n",
            "\n",
            "Test 1: What are the best ways to travel from Mumbai to Goa?\n",
            "❓ Needs clarification:\n",
            "   1. What is the traveler's budget?\n",
            "   2. What is the traveler's preferred mode of transportation (e.g., train, bus, car, flight)?\n",
            "   3. How much time does the traveler have for the journey?\n",
            "   4. How many people are traveling?\n",
            "   5. What is the traveler's definition of 'best' (e.g., fastest, cheapest, most comfortable)?\n",
            "\n",
            "Test 2: Research about AI\n",
            "❓ Needs clarification:\n",
            "   1. What specific aspect of AI are you interested in? (e.g., AI ethics, AI in healthcare, AI algorithms, the history of AI, etc.)\n",
            "   2. What is the scope of your research? (e.g., a literature review, a comparative analysis, a case study, etc.)\n",
            "\n",
            "Test 3: Is Rahul better than Vishal?\n",
            "❓ Needs clarification:\n",
            "   1. Better in what aspect? (e.g., academic performance, athletic ability, artistic skill, personality traits)\n",
            "   2. What specific metrics or criteria will be used to compare Rahul and Vishal?\n",
            "\n",
            "Test 4: Compare programming languages\n",
            "❓ Needs clarification:\n",
            "   1. Which programming languages should be compared?\n",
            "   2. What specific aspects of the programming languages should be compared (e.g., syntax, performance, ease of use, community support, specific applications)?\n",
            "   3. What is the intended audience for this comparison (e.g., beginners, experienced programmers, specific industry)?\n",
            "   4. What is the scope of the comparison (e.g., a brief overview, in-depth analysis)?\n",
            "   5. What metrics will be used to compare the languages?\n",
            "\n"
          ]
        }
      ]
    }
  ]
}